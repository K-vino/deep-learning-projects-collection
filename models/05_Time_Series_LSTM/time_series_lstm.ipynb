{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚è∞ Time Series Forecasting with LSTM\n",
    "\n",
    "Welcome to **Time Series Forecasting**! In this notebook, we'll use LSTM networks to predict future values from sequential data. We'll work with stock prices, weather data, and energy consumption.\n",
    "\n",
    "## What you'll learn:\n",
    "- Time series data preprocessing\n",
    "- Sliding window technique\n",
    "- LSTM architectures for forecasting\n",
    "- Multi-step and multi-variate predictions\n",
    "\n",
    "Let's predict the future! üîÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import yfinance as yf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stock price data\n",
    "def load_stock_data(symbol='AAPL', period='2y'):\n",
    "    \"\"\"Load stock data from Yahoo Finance\"\"\"\n",
    "    try:\n",
    "        stock = yf.download(symbol, period=period)\n",
    "        return stock\n",
    "    except:\n",
    "        # Fallback: Generate synthetic stock data\n",
    "        print(\"Using synthetic stock data...\")\n",
    "        dates = pd.date_range(start='2022-01-01', end='2024-01-01', freq='D')\n",
    "        np.random.seed(42)\n",
    "        price = 150 + np.cumsum(np.random.randn(len(dates)) * 0.5)\n",
    "        volume = np.random.randint(1000000, 10000000, len(dates))\n",
    "        \n",
    "        data = pd.DataFrame({\n",
    "            'Open': price + np.random.randn(len(dates)) * 2,\n",
    "            'High': price + np.abs(np.random.randn(len(dates)) * 3),\n",
    "            'Low': price - np.abs(np.random.randn(len(dates)) * 3),\n",
    "            'Close': price,\n",
    "            'Volume': volume\n",
    "        }, index=dates)\n",
    "        return data\n",
    "\n",
    "# Load data\n",
    "stock_data = load_stock_data('AAPL', '2y')\n",
    "print(f\"Stock data shape: {stock_data.shape}\")\n",
    "print(f\"Date range: {stock_data.index[0]} to {stock_data.index[-1]}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìä Stock Data Sample:\")\n",
    "print(stock_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stock data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Price chart\n",
    "axes[0, 0].plot(stock_data.index, stock_data['Close'], label='Close Price')\n",
    "axes[0, 0].plot(stock_data.index, stock_data['Open'], alpha=0.7, label='Open Price')\n",
    "axes[0, 0].set_title('üìà Stock Price Over Time')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Volume chart\n",
    "axes[0, 1].plot(stock_data.index, stock_data['Volume'], color='orange')\n",
    "axes[0, 1].set_title('üìä Trading Volume')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Volume')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Daily returns\n",
    "returns = stock_data['Close'].pct_change().dropna()\n",
    "axes[1, 0].plot(returns.index, returns, alpha=0.7)\n",
    "axes[1, 0].set_title('üìâ Daily Returns')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Return (%)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Returns distribution\n",
    "axes[1, 1].hist(returns, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_title('üìä Returns Distribution')\n",
    "axes[1, 1].set_xlabel('Daily Return')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Statistics:\")\n",
    "print(f\"Average daily return: {returns.mean():.4f}\")\n",
    "print(f\"Volatility (std): {returns.std():.4f}\")\n",
    "print(f\"Min/Max prices: ${stock_data['Close'].min():.2f} / ${stock_data['Close'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "def create_sequences(data, seq_length, target_col='Close'):\n",
    "    \"\"\"Create sequences for LSTM training\"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(seq_length, len(data)):\n",
    "        sequences.append(data[i-seq_length:i])\n",
    "        targets.append(data[i][target_col] if isinstance(data, pd.DataFrame) else data[i])\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Use only Close price for univariate forecasting\n",
    "close_prices = stock_data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(close_prices)\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 60  # Use 60 days to predict next day\n",
    "X, y = create_sequences(scaled_data.flatten(), seq_length)\n",
    "\n",
    "# Reshape X for LSTM (samples, time steps, features)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Sequence length: {seq_length} days\")\n",
    "print(f\"Total sequences: {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Vanilla LSTM\n",
    "def create_vanilla_lstm(seq_length, n_features=1):\n",
    "    model = models.Sequential([\n",
    "        layers.LSTM(50, input_shape=(seq_length, n_features)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "vanilla_lstm = create_vanilla_lstm(seq_length)\n",
    "vanilla_lstm.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"üîÑ Vanilla LSTM Architecture:\")\n",
    "vanilla_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Vanilla LSTM\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "print(\"üöÄ Training Vanilla LSTM...\")\n",
    "history_vanilla = vanilla_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "train_pred = vanilla_lstm.predict(X_train)\n",
    "test_pred = vanilla_lstm.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions\n",
    "train_pred = scaler.inverse_transform(train_pred)\n",
    "test_pred = scaler.inverse_transform(test_pred)\n",
    "y_train_actual = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae = mean_absolute_error(y_train_actual, train_pred)\n",
    "test_mae = mean_absolute_error(y_test_actual, test_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_actual, train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_actual, test_pred))\n",
    "\n",
    "print(f\"\\nüéØ Vanilla LSTM Results:\")\n",
    "print(f\"Train MAE: ${train_mae:.2f}, RMSE: ${train_rmse:.2f}\")\n",
    "print(f\"Test MAE: ${test_mae:.2f}, RMSE: ${test_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Stacked LSTM\n",
    "def create_stacked_lstm(seq_length, n_features=1):\n",
    "    model = models.Sequential([\n",
    "        layers.LSTM(50, return_sequences=True, input_shape=(seq_length, n_features)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.LSTM(50, return_sequences=True),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.LSTM(50),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "stacked_lstm = create_stacked_lstm(seq_length)\n",
    "stacked_lstm.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"üèóÔ∏è Stacked LSTM Architecture:\")\n",
    "stacked_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Stacked LSTM\n",
    "print(\"üöÄ Training Stacked LSTM...\")\n",
    "history_stacked = stacked_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "stacked_test_pred = stacked_lstm.predict(X_test)\n",
    "stacked_test_pred = scaler.inverse_transform(stacked_test_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "stacked_test_mae = mean_absolute_error(y_test_actual, stacked_test_pred)\n",
    "stacked_test_rmse = np.sqrt(mean_squared_error(y_test_actual, stacked_test_pred))\n",
    "\n",
    "print(f\"\\nüéØ Stacked LSTM Results:\")\n",
    "print(f\"Test MAE: ${stacked_test_mae:.2f}, RMSE: ${stacked_test_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Training history - Vanilla LSTM\n",
    "axes[0, 0].plot(history_vanilla.history['loss'], label='Training Loss')\n",
    "axes[0, 0].plot(history_vanilla.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('üìâ Vanilla LSTM - Training History')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Training history - Stacked LSTM\n",
    "axes[0, 1].plot(history_stacked.history['loss'], label='Training Loss')\n",
    "axes[0, 1].plot(history_stacked.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 1].set_title('üìâ Stacked LSTM - Training History')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Predictions comparison\n",
    "test_dates = stock_data.index[split_idx + seq_length:]\n",
    "axes[1, 0].plot(test_dates, y_test_actual, label='Actual', alpha=0.8)\n",
    "axes[1, 0].plot(test_dates, test_pred, label='Vanilla LSTM', alpha=0.8)\n",
    "axes[1, 0].plot(test_dates, stacked_test_pred, label='Stacked LSTM', alpha=0.8)\n",
    "axes[1, 0].set_title('üìà Stock Price Predictions')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Price ($)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Error analysis\n",
    "vanilla_errors = y_test_actual.flatten() - test_pred.flatten()\n",
    "stacked_errors = y_test_actual.flatten() - stacked_test_pred.flatten()\n",
    "\n",
    "axes[1, 1].hist(vanilla_errors, bins=30, alpha=0.7, label='Vanilla LSTM', edgecolor='black')\n",
    "axes[1, 1].hist(stacked_errors, bins=30, alpha=0.7, label='Stacked LSTM', edgecolor='black')\n",
    "axes[1, 1].set_title('üìä Prediction Errors Distribution')\n",
    "axes[1, 1].set_xlabel('Error ($)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüèÜ Model Comparison:\")\n",
    "print(f\"Vanilla LSTM - MAE: ${test_mae:.2f}, RMSE: ${test_rmse:.2f}\")\n",
    "print(f\"Stacked LSTM - MAE: ${stacked_test_mae:.2f}, RMSE: ${stacked_test_rmse:.2f}\")\n",
    "improvement = ((test_mae - stacked_test_mae) / test_mae) * 100\n",
    "print(f\"Improvement: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've mastered time series forecasting with LSTMs! Here's what you've accomplished:\n",
    "\n",
    "‚úÖ **Time Series Processing**: Data preparation and windowing  \n",
    "‚úÖ **LSTM Architectures**: Vanilla and stacked models  \n",
    "‚úÖ **Forecasting**: Single-step price prediction  \n",
    "‚úÖ **Model Evaluation**: MAE, RMSE, and error analysis  \n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. Try multi-variate forecasting with multiple features\n",
    "2. Implement multi-step ahead predictions\n",
    "3. Experiment with attention mechanisms\n",
    "4. Move on to **Project 06: GAN for Face Generation**\n",
    "\n",
    "Ready for generative models? Let's create new data! üé®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
