{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Fine-tuning BERT for Sentiment Analysis\n",
    "\n",
    "Welcome to **BERT fine-tuning**! In this notebook, we'll leverage the power of pre-trained language models to achieve state-of-the-art sentiment analysis results with minimal training time.\n",
    "\n",
    "## What you'll learn:\n",
    "- BERT architecture and bidirectional attention\n",
    "- Transfer learning with pre-trained models\n",
    "- Fine-tuning strategies and techniques\n",
    "- Attention visualization and interpretability\n",
    "\n",
    "Let's achieve SOTA results! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install transformers datasets torch torchvision torchaudio\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers and PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, pipeline\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sentiment dataset\n",
    "def create_sentiment_dataset():\n",
    "    \"\"\"Create a sample sentiment analysis dataset\"\"\"\n",
    "    positive_samples = [\n",
    "        \"This movie is absolutely fantastic! I loved every minute of it.\",\n",
    "        \"Amazing performance by the actors. Highly recommended!\",\n",
    "        \"One of the best films I've ever seen. Brilliant storytelling.\",\n",
    "        \"Incredible cinematography and outstanding direction.\",\n",
    "        \"A masterpiece that will be remembered for years to come.\",\n",
    "        \"Excellent plot with great character development.\",\n",
    "        \"Wonderful experience! The movie exceeded my expectations.\",\n",
    "        \"Perfect blend of action, drama, and emotion.\",\n",
    "        \"Outstanding performances from the entire cast.\",\n",
    "        \"A truly inspiring and uplifting story.\"\n",
    "    ] * 50  # Repeat for more samples\n",
    "    \n",
    "    negative_samples = [\n",
    "        \"This movie was terrible. Complete waste of time.\",\n",
    "        \"Boring plot and poor acting. Very disappointing.\",\n",
    "        \"One of the worst films I've ever watched.\",\n",
    "        \"Awful direction and terrible screenplay.\",\n",
    "        \"I couldn't even finish watching this movie.\",\n",
    "        \"Poor character development and weak storyline.\",\n",
    "        \"Completely overrated. Don't waste your money.\",\n",
    "        \"Terrible acting and confusing plot.\",\n",
    "        \"Disappointing performances from all actors.\",\n",
    "        \"A complete disaster of a movie.\"\n",
    "    ] * 50  # Repeat for more samples\n",
    "    \n",
    "    # Create dataset\n",
    "    texts = positive_samples + negative_samples\n",
    "    labels = [1] * len(positive_samples) + [0] * len(negative_samples)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    data = list(zip(texts, labels))\n",
    "    np.random.shuffle(data)\n",
    "    texts, labels = zip(*data)\n",
    "    \n",
    "    return list(texts), list(labels)\n",
    "\n",
    "# Create dataset\n",
    "texts, labels = create_sentiment_dataset()\n",
    "\n",
    "print(f\"Dataset size: {len(texts)} samples\")\n",
    "print(f\"Positive samples: {sum(labels)}\")\n",
    "print(f\"Negative samples: {len(labels) - sum(labels)}\")\n",
    "\n",
    "# Display sample texts\n",
    "print(\"\\nüìù Sample Texts:\")\n",
    "for i in range(5):\n",
    "    sentiment = \"Positive\" if labels[i] == 1 else \"Negative\"\n",
    "    print(f\"{sentiment}: {texts[i]}\")\n",
    "\n",
    "# Split into train/test\n",
    "split_idx = int(0.8 * len(texts))\n",
    "train_texts, test_texts = texts[:split_idx], texts[split_idx:]\n",
    "train_labels, test_labels = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "print(f\"\\nTrain samples: {len(train_texts)}\")\n",
    "print(f\"Test samples: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer and model\n",
    "MODEL_NAME = \"distilbert-base-uncased\"  # Smaller, faster version of BERT\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=2,  # Binary classification\n",
    "    output_attentions=True,  # For attention visualization\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Loaded {MODEL_NAME}\")\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")\n",
    "print(f\"Tokenizer vocabulary size: {tokenizer.vocab_size:,}\")\n",
    "\n",
    "# Test tokenization\n",
    "sample_text = \"This movie is absolutely fantastic!\"\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "token_ids = tokenizer.encode(sample_text)\n",
    "\n",
    "print(f\"\\nüî§ Tokenization Example:\")\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "print(f\"Decoded: {tokenizer.decode(token_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"‚úÖ Created datasets\")\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Test dataset\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nüìä Sample from dataset:\")\n",
    "print(f\"Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"Attention mask shape: {sample['attention_mask'].shape}\")\n",
    "print(f\"Label: {sample['labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer configured\")\n",
    "print(f\"Training epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "print(\"üöÄ Starting BERT fine-tuning...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nüéâ Fine-tuning completed!\")\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"\\nüìä Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = test_labels\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"üéØ Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('üéØ Confusion Matrix - BERT Sentiment Analysis')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Training history\n",
    "if hasattr(trainer.state, 'log_history'):\n",
    "    log_history = trainer.state.log_history\n",
    "    \n",
    "    # Extract training and evaluation metrics\n",
    "    train_loss = [log['train_loss'] for log in log_history if 'train_loss' in log]\n",
    "    eval_accuracy = [log['eval_accuracy'] for log in log_history if 'eval_accuracy' in log]\n",
    "    \n",
    "    if train_loss and eval_accuracy:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Training loss\n",
    "        ax1.plot(train_loss)\n",
    "        ax1.set_title('üìâ Training Loss')\n",
    "        ax1.set_xlabel('Step')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Evaluation accuracy\n",
    "        ax2.plot(eval_accuracy, marker='o')\n",
    "        ax2.set_title('üìà Evaluation Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Test with custom examples\n",
    "test_examples = [\n",
    "    \"This movie is absolutely amazing! I loved it.\",\n",
    "    \"Terrible film, complete waste of time.\",\n",
    "    \"The acting was decent but the plot was confusing.\",\n",
    "    \"One of the best movies I've ever seen!\",\n",
    "    \"Not great, not terrible. Just okay.\"\n",
    "]\n",
    "\n",
    "print(\"üé≠ Sentiment Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text in test_examples:\n",
    "    result = sentiment_pipeline(text)[0]\n",
    "    label = \"Positive\" if result['label'] == 'LABEL_1' else \"Negative\"\n",
    "    confidence = result['score']\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {label} (Confidence: {confidence:.3f})\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine_tuned_bert')\n",
    "tokenizer.save_pretrained('./fine_tuned_bert')\n",
    "\n",
    "print(\"\\nüíæ Model saved to './fine_tuned_bert'\")\n",
    "\n",
    "print(f\"\\nüìä Final Results Summary:\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Samples: {len(train_texts)}\")\n",
    "print(f\"Test Samples: {len(test_texts)}\")\n",
    "print(f\"Max Sequence Length: {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully fine-tuned BERT for sentiment analysis! Here's what you've accomplished:\n",
    "\n",
    "‚úÖ **BERT Fine-tuning**: Adapted pre-trained model for sentiment analysis  \n",
    "‚úÖ **Transfer Learning**: Leveraged pre-trained knowledge  \n",
    "‚úÖ **Tokenization**: Processed text for BERT input format  \n",
    "‚úÖ **High Accuracy**: Achieved excellent classification performance  \n",
    "‚úÖ **Pipeline Creation**: Built ready-to-use sentiment analyzer  \n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. Try different BERT variants (RoBERTa, ALBERT)\n",
    "2. Experiment with different datasets\n",
    "3. Implement attention visualization\n",
    "4. Move on to **Project 11: GPT-2 for Text Generation**\n",
    "\n",
    "Ready for autoregressive text generation? Let's generate text! üìù"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
