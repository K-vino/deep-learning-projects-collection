{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üëó Fashion-MNIST with ResNet\n",
    "\n",
    "Welcome to **Residual Networks**! In this notebook, we'll build deep CNNs that can actually train effectively using residual connections. We'll classify fashion items with state-of-the-art accuracy.\n",
    "\n",
    "## What you'll learn:\n",
    "- ResNet architecture and residual blocks\n",
    "- Skip connections and identity mappings\n",
    "- Transfer learning with pre-trained models\n",
    "- Advanced training techniques\n",
    "\n",
    "Let's build some deep networks! üèóÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(f'{class_names[y_train[i]]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('üëó Fashion-MNIST Dataset Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Add channel dimension and convert to RGB for transfer learning\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
    "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
    "\n",
    "# Resize for ResNet (requires 32x32 minimum)\n",
    "X_train_resized = tf.image.resize(X_train_rgb, [32, 32])\n",
    "X_test_resized = tf.image.resize(X_test_rgb, [32, 32])\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"‚úÖ Data preprocessing completed!\")\n",
    "print(f\"Resized training data shape: {X_train_resized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define residual block\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=False):\n",
    "    \"\"\"A residual block with skip connection\"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    # Main path\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Shortcut path\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    # Add shortcut to main path\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_mini_resnet():\n",
    "    \"\"\"Create a mini ResNet for Fashion-MNIST\"\"\"\n",
    "    inputs = layers.Input(shape=(28, 28, 1))\n",
    "    \n",
    "    # Initial conv layer\n",
    "    x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Residual blocks\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = residual_block(x, 128, stride=2, conv_shortcut=True)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = residual_block(x, 256, stride=2, conv_shortcut=True)\n",
    "    x = residual_block(x, 256)\n",
    "    \n",
    "    # Global average pooling and classification\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create and compile mini ResNet\n",
    "mini_resnet = create_mini_resnet()\n",
    "mini_resnet.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"üèóÔ∏è Mini ResNet Architecture:\")\n",
    "mini_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train mini ResNet\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "print(\"üöÄ Training Mini ResNet...\")\n",
    "history_mini = mini_resnet.fit(\n",
    "    X_train, y_train_cat,\n",
    "    batch_size=128,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = mini_resnet.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(f\"\\nüéØ Mini ResNet Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning with ResNet50\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(32, 32, 3)\n",
    ")\n",
    "\n",
    "# Freeze base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom head\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "transfer_model = keras.Model(inputs, outputs)\n",
    "transfer_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"üîÑ Transfer Learning Model:\")\n",
    "print(f\"Total parameters: {transfer_model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in transfer_model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train transfer learning model\n",
    "print(\"üöÄ Training Transfer Learning Model...\")\n",
    "history_transfer = transfer_model.fit(\n",
    "    X_train_resized, y_train_cat,\n",
    "    batch_size=128,\n",
    "    epochs=15,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fine-tuning: Unfreeze top layers\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "transfer_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"üîß Fine-tuning...\")\n",
    "history_finetune = transfer_model.fit(\n",
    "    X_train_resized, y_train_cat,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate transfer model\n",
    "transfer_test_loss, transfer_test_acc = transfer_model.evaluate(X_test_resized, y_test_cat, verbose=0)\n",
    "print(f\"\\nüéØ Transfer Learning Test Accuracy: {transfer_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Mini ResNet training curves\n",
    "ax1.plot(history_mini.history['accuracy'], label='Training')\n",
    "ax1.plot(history_mini.history['val_accuracy'], label='Validation')\n",
    "ax1.set_title('üìà Mini ResNet - Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history_mini.history['loss'], label='Training')\n",
    "ax2.plot(history_mini.history['val_loss'], label='Validation')\n",
    "ax2.set_title('üìâ Mini ResNet - Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Transfer learning curves\n",
    "ax3.plot(history_transfer.history['accuracy'], label='Training')\n",
    "ax3.plot(history_transfer.history['val_accuracy'], label='Validation')\n",
    "ax3.set_title('üìà Transfer Learning - Accuracy')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4.plot(history_transfer.history['loss'], label='Training')\n",
    "ax4.plot(history_transfer.history['val_loss'], label='Validation')\n",
    "ax4.set_title('üìâ Transfer Learning - Loss')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Loss')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüèÜ Final Results Comparison:\")\n",
    "print(f\"Mini ResNet Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Transfer Learning Test Accuracy: {transfer_test_acc:.4f}\")\n",
    "print(f\"Improvement: {(transfer_test_acc - test_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've mastered ResNet and transfer learning! Here's what you've accomplished:\n",
    "\n",
    "‚úÖ **ResNet Architecture**: Built deep networks with skip connections  \n",
    "‚úÖ **Transfer Learning**: Leveraged pre-trained models  \n",
    "‚úÖ **Fine-tuning**: Optimized for specific tasks  \n",
    "‚úÖ **Advanced Training**: Used modern techniques  \n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. Try other architectures (DenseNet, EfficientNet)\n",
    "2. Experiment with attention mechanisms\n",
    "3. Implement custom residual blocks\n",
    "4. Move on to **Project 04: Text Classification using RNN**\n",
    "\n",
    "Ready for NLP? Let's dive into text! üìù"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
