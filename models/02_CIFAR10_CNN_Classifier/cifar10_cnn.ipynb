{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🖼️ CIFAR-10 CNN Classifier\n",
    "\n",
    "Welcome to your first **Convolutional Neural Network** project! In this notebook, we'll build increasingly sophisticated CNNs to classify images from the CIFAR-10 dataset.\n",
    "\n",
    "## What you'll learn:\n",
    "- CNN architecture and components\n",
    "- Data augmentation techniques\n",
    "- Regularization methods\n",
    "- Model optimization strategies\n",
    "\n",
    "Let's start building some powerful image classifiers! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"📚 Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Load and Explore CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Image dimensions: {X_train.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i])\n",
    "    ax.set_title(f'{class_names[y_train[i][0]]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('🖼️ CIFAR-10 Dataset Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar([class_names[i] for i in unique], counts)\n",
    "plt.title('📊 Class Distribution in Training Set')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "X_train_norm = X_train.astype('float32') / 255.0\n",
    "X_test_norm = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"✅ Data preprocessing completed!\")\n",
    "print(f\"Normalized training data range: [{X_train_norm.min():.2f}, {X_train_norm.max():.2f}]\")\n",
    "print(f\"Categorical labels shape: {y_train_cat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Model 1: Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_cnn():\n",
    "    \"\"\"Create a basic CNN model\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile basic model\n",
    "basic_model = create_basic_cnn()\n",
    "basic_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "basic_model.summary()\n",
    "\n",
    "# Visualize model architecture\n",
    "keras.utils.plot_model(basic_model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train basic model\n",
    "print(\"🚀 Training Basic CNN...\")\n",
    "basic_history = basic_model.fit(\n",
    "    X_train_norm, y_train_cat,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate basic model\n",
    "basic_test_loss, basic_test_acc = basic_model.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"\\n🎯 Basic CNN Test Accuracy: {basic_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 Model 2: Improved CNN with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_cnn():\n",
    "    \"\"\"Create an improved CNN with batch normalization and dropout\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create improved model\n",
    "improved_model = create_improved_cnn()\n",
    "improved_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"🔥 Improved CNN Architecture:\")\n",
    "improved_model.summary()\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🎨 Data Augmentation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create data augmentation generator\\n\",\n",
    "    \"datagen = ImageDataGenerator(\\n\",\n",
    "    \"    rotation_range=15,\\n\",\n",
    "    \"    width_shift_range=0.1,\\n\",\n",
    "    \"    height_shift_range=0.1,\\n\",\n",
    "    \"    horizontal_flip=True,\\n\",\n",
    "    \"    zoom_range=0.2,\\n\",\n",
    "    \"    shear_range=0.1,\\n\",\n",
    "    \"    fill_mode='nearest'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fit the generator on training data\\n\",\n",
    "    \"datagen.fit(X_train_norm)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize augmented images\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 5, figsize=(15, 8))\\n\",\n",
    "    \"sample_image = X_train_norm[0:1]  # Take first image\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate augmented versions\\n\",\n",
    "    \"augmented_images = []\\n\",\n",
    "    \"for batch in datagen.flow(sample_image, batch_size=1):\\n\",\n",
    "    \"    augmented_images.append(batch[0])\\n\",\n",
    "    \"    if len(augmented_images) >= 10:\\n\",\n",
    "    \"        break\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot original and augmented images\\n\",\n",
    "    \"for i, ax in enumerate(axes.flat):\\n\",\n",
    "    \"    if i == 0:\\n\",\n",
    "    \"        ax.imshow(sample_image[0])\\n\",\n",
    "    \"        ax.set_title('Original')\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        ax.imshow(augmented_images[i-1])\\n\",\n",
    "    \"        ax.set_title(f'Augmented {i}')\\n\",\n",
    "    \"    ax.axis('off')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.suptitle('🎨 Data Augmentation Examples', fontsize=16)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup callbacks\\n\",\n",
    "    \"callbacks = [\\n\",\n",
    "    \"    EarlyStopping(patience=5, restore_best_weights=True),\\n\",\n",
    "    \"    ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-7),\\n\",\n",
    "    \"    ModelCheckpoint('models/improved_cnn.h5', save_best_only=True)\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train improved model with data augmentation\\n\",\n",
    "    \"print(\\\"🚀 Training Improved CNN with Data Augmentation...\\\")\\n\",\n",
    "    \"improved_history = improved_model.fit(\\n\",\n",
    "    \"    datagen.flow(X_train_norm, y_train_cat, batch_size=32),\\n\",\n",
    "    \"    steps_per_epoch=len(X_train_norm) // 32,\\n\",\n",
    "    \"    epochs=50,\\n\",\n",
    "    \"    validation_data=(X_test_norm, y_test_cat),\\n\",\n",
    "    \"    callbacks=callbacks,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate improved model\\n\",\n",
    "    \"improved_test_loss, improved_test_acc = improved_model.evaluate(X_test_norm, y_test_cat, verbose=0)\\n\",\n",
    "    \"print(f\\\"\\\\n🎯 Improved CNN Test Accuracy: {improved_test_acc:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 📈 Training Results Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot training history comparison\\n\",\n",
    "    \"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Basic model accuracy\\n\",\n",
    "    \"ax1.plot(basic_history.history['accuracy'], label='Training')\\n\",\n",
    "    \"ax1.plot(basic_history.history['val_accuracy'], label='Validation')\\n\",\n",
    "    \"ax1.set_title('📈 Basic CNN - Accuracy')\\n\",\n",
    "    \"ax1.set_xlabel('Epoch')\\n\",\n",
    "    \"ax1.set_ylabel('Accuracy')\\n\",\n",
    "    \"ax1.legend()\\n\",\n",
    "    \"ax1.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Basic model loss\\n\",\n",
    "    \"ax2.plot(basic_history.history['loss'], label='Training')\\n\",\n",
    "    \"ax2.plot(basic_history.history['val_loss'], label='Validation')\\n\",\n",
    "    \"ax2.set_title('📉 Basic CNN - Loss')\\n\",\n",
    "    \"ax2.set_xlabel('Epoch')\\n\",\n",
    "    \"ax2.set_ylabel('Loss')\\n\",\n",
    "    \"ax2.legend()\\n\",\n",
    "    \"ax2.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Improved model accuracy\\n\",\n",
    "    \"ax3.plot(improved_history.history['accuracy'], label='Training')\\n\",\n",
    "    \"ax3.plot(improved_history.history['val_accuracy'], label='Validation')\\n\",\n",
    "    \"ax3.set_title('📈 Improved CNN - Accuracy')\\n\",\n",
    "    \"ax3.set_xlabel('Epoch')\\n\",\n",
    "    \"ax3.set_ylabel('Accuracy')\\n\",\n",
    "    \"ax3.legend()\\n\",\n",
    "    \"ax3.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Improved model loss\\n\",\n",
    "    \"ax4.plot(improved_history.history['loss'], label='Training')\\n\",\n",
    "    \"ax4.plot(improved_history.history['val_loss'], label='Validation')\\n\",\n",
    "    \"ax4.set_title('📉 Improved CNN - Loss')\\n\",\n",
    "    \"ax4.set_xlabel('Epoch')\\n\",\n",
    "    \"ax4.set_ylabel('Loss')\\n\",\n",
    "    \"ax4.legend()\\n\",\n",
    "    \"ax4.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Model comparison\\n\",\n",
    "    \"print(\\\"\\\\n🏆 Model Comparison:\\\")\\n\",\n",
    "    \"print(f\\\"Basic CNN Test Accuracy: {basic_test_acc:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Improved CNN Test Accuracy: {improved_test_acc:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Improvement: {(improved_test_acc - basic_test_acc)*100:.2f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🔍 Model Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Make predictions\\n\",\n",
    "    \"y_pred = improved_model.predict(X_test_norm)\\n\",\n",
    "    \"y_pred_classes = np.argmax(y_pred, axis=1)\\n\",\n",
    "    \"y_true_classes = np.argmax(y_test_cat, axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Confusion matrix\\n\",\n",
    "    \"cm = confusion_matrix(y_true_classes, y_pred_classes)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 10))\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n\",\n",
    "    \"            xticklabels=class_names, yticklabels=class_names)\\n\",\n",
    "    \"plt.title('🎯 Confusion Matrix - Improved CNN')\\n\",\n",
    "    \"plt.xlabel('Predicted')\\n\",\n",
    "    \"plt.ylabel('Actual')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.yticks(rotation=0)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Classification report\\n\",\n",
    "    \"print(\\\"\\\\n📊 Classification Report:\\\")\\n\",\n",
    "    \"print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 🎉 Congratulations!\\n\",\n",
    "    \"\\n\",\n",
    "    \"You've successfully built and trained CNNs for image classification! Here's what you've accomplished:\\n\",\n",
    "    \"\\n\",\n",
    "    \"✅ **Basic CNN**: Understanding CNN architecture  \\n\",\n",
    "    \"✅ **Improved CNN**: Adding regularization and optimization  \\n\",\n",
    "    \"✅ **Data Augmentation**: Improving generalization  \\n\",\n",
    "    \"✅ **Model Analysis**: Evaluating and comparing performance  \\n\",\n",
    "    \"\\n\",\n",
    "    \"### 🚀 Next Steps:\\n\",\n",
    "    \"1. Experiment with different architectures (ResNet, VGG, etc.)\\n\",\n",
    "    \"2. Try transfer learning with pre-trained models\\n\",\n",
    "    \"3. Implement custom data augmentation techniques\\n\",\n",
    "    \"4. Move on to **Project 03: Fashion-MNIST with ResNet**\\n\",\n",
    "    \"\\n\",\n",
    "    \"Keep building and happy coding! 🎯\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "   \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
