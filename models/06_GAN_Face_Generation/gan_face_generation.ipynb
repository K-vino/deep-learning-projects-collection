{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ GAN for Face Generation\n",
    "\n",
    "Welcome to **Generative Adversarial Networks**! In this notebook, we'll create realistic face images from random noise using the power of adversarial training.\n",
    "\n",
    "## What you'll learn:\n",
    "- GAN architecture and adversarial training\n",
    "- Generator and discriminator design\n",
    "- DCGAN implementation\n",
    "- Techniques for stable GAN training\n",
    "\n",
    "Let's create new faces! ðŸ‘¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "# Set up directories\n",
    "os.makedirs('generated_images', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic face dataset for demonstration\n",
    "def create_synthetic_faces(num_samples=10000, img_size=64):\n",
    "    \"\"\"Create synthetic face-like images for training\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create face-like patterns\n",
    "    faces = []\n",
    "    for i in range(num_samples):\n",
    "        # Create a face-like structure\n",
    "        face = np.zeros((img_size, img_size, 3))\n",
    "        \n",
    "        # Face oval\n",
    "        center_x, center_y = img_size // 2, img_size // 2\n",
    "        for x in range(img_size):\n",
    "            for y in range(img_size):\n",
    "                dist = ((x - center_x) ** 2 / (img_size // 3) ** 2 + \n",
    "                       (y - center_y) ** 2 / (img_size // 2.5) ** 2)\n",
    "                if dist < 1:\n",
    "                    face[x, y] = [0.8, 0.7, 0.6]  # Skin tone\n",
    "        \n",
    "        # Eyes\n",
    "        eye_y = center_y - img_size // 6\n",
    "        for eye_x in [center_x - img_size // 6, center_x + img_size // 6]:\n",
    "            for x in range(eye_x - 3, eye_x + 4):\n",
    "                for y in range(eye_y - 2, eye_y + 3):\n",
    "                    if 0 <= x < img_size and 0 <= y < img_size:\n",
    "                        face[x, y] = [0.1, 0.1, 0.1]  # Dark eyes\n",
    "        \n",
    "        # Nose\n",
    "        nose_x, nose_y = center_x, center_y\n",
    "        for x in range(nose_x - 1, nose_x + 2):\n",
    "            for y in range(nose_y - 2, nose_y + 3):\n",
    "                if 0 <= x < img_size and 0 <= y < img_size:\n",
    "                    face[x, y] = [0.7, 0.6, 0.5]  # Nose shadow\n",
    "        \n",
    "        # Mouth\n",
    "        mouth_y = center_y + img_size // 6\n",
    "        for x in range(center_x - 4, center_x + 5):\n",
    "            for y in range(mouth_y - 1, mouth_y + 2):\n",
    "                if 0 <= x < img_size and 0 <= y < img_size:\n",
    "                    face[x, y] = [0.6, 0.3, 0.3]  # Mouth\n",
    "        \n",
    "        # Add noise for variation\n",
    "        noise = np.random.normal(0, 0.1, face.shape)\n",
    "        face = np.clip(face + noise, 0, 1)\n",
    "        \n",
    "        faces.append(face)\n",
    "    \n",
    "    return np.array(faces)\n",
    "\n",
    "# Create dataset\n",
    "print(\"ðŸŽ­ Creating synthetic face dataset...\")\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "NOISE_DIM = 100\n",
    "\n",
    "# Generate synthetic faces\n",
    "faces_data = create_synthetic_faces(5000, IMG_SIZE)\n",
    "print(f\"Dataset shape: {faces_data.shape}\")\n",
    "\n",
    "# Normalize to [-1, 1] for GAN training\n",
    "faces_data = (faces_data - 0.5) * 2\n",
    "\n",
    "# Create dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(faces_data)\n",
    "dataset = dataset.shuffle(1000).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Visualize sample faces\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Convert back to [0, 1] for display\n",
    "    img = (faces_data[i] + 1) / 2\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f'Sample {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('ðŸŽ­ Synthetic Face Dataset Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Generator\n",
    "def build_generator(noise_dim=100, img_size=64):\n",
    "    \"\"\"Build DCGAN Generator\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Dense layer to start\n",
    "        layers.Dense(8 * 8 * 256, input_shape=(noise_dim,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((8, 8, 256)),\n",
    "        \n",
    "        # Upsample to 16x16\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        # Upsample to 32x32\n",
    "        layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        # Upsample to 64x64\n",
    "        layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same'),\n",
    "        layers.Tanh()  # Output in [-1, 1]\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build Discriminator\n",
    "def build_discriminator(img_size=64):\n",
    "    \"\"\"Build DCGAN Discriminator\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', \n",
    "                     input_shape=(img_size, img_size, 3)),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Downsample to 16x16\n",
    "        layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Downsample to 8x8\n",
    "        layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Classification layer\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create models\n",
    "generator = build_generator(NOISE_DIM, IMG_SIZE)\n",
    "discriminator = build_discriminator(IMG_SIZE)\n",
    "\n",
    "print(\"ðŸŽ¨ Generator Architecture:\")\n",
    "generator.summary()\n",
    "\n",
    "print(\"\\nðŸ” Discriminator Architecture:\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions and optimizers\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "\n",
    "print(\"âœ… Loss functions and optimizers defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "# Function to generate and save images\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        # Convert from [-1, 1] to [0, 1]\n",
    "        img = (predictions[i] + 1) / 2\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Generated Images - Epoch {epoch}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'generated_images/image_at_epoch_{epoch:04d}.png')\n",
    "    plt.show()\n",
    "\n",
    "print(\"ðŸš€ Training functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GAN\n",
    "EPOCHS = 50\n",
    "num_examples_to_generate = 16\n",
    "seed = tf.random.normal([num_examples_to_generate, NOISE_DIM])\n",
    "\n",
    "# Track losses\n",
    "gen_losses = []\n",
    "disc_losses = []\n",
    "\n",
    "print(\"ðŸŽ¨ Starting GAN Training...\")\n",
    "print(f\"Epochs: {EPOCHS}, Batch Size: {BATCH_SIZE}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_gen_loss = []\n",
    "    epoch_disc_loss = []\n",
    "    \n",
    "    # Training loop\n",
    "    for batch in tqdm(dataset, desc=f'Epoch {epoch+1}/{EPOCHS}'):\n",
    "        gen_loss, disc_loss = train_step(batch)\n",
    "        epoch_gen_loss.append(gen_loss)\n",
    "        epoch_disc_loss.append(disc_loss)\n",
    "    \n",
    "    # Record average losses\n",
    "    avg_gen_loss = tf.reduce_mean(epoch_gen_loss)\n",
    "    avg_disc_loss = tf.reduce_mean(epoch_disc_loss)\n",
    "    gen_losses.append(avg_gen_loss)\n",
    "    disc_losses.append(avg_disc_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch+1}: Gen Loss: {avg_gen_loss:.4f}, Disc Loss: {avg_disc_loss:.4f}')\n",
    "    \n",
    "    # Generate images every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progress\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(gen_losses, label='Generator Loss', alpha=0.8)\n",
    "axes[0].plot(disc_losses, label='Discriminator Loss', alpha=0.8)\n",
    "axes[0].set_title('ðŸ“‰ GAN Training Losses')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Final generated images\n",
    "final_images = generator(seed, training=False)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('ðŸŽ¨ Final Generated Faces')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show grid of final generated faces\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = (final_images[i] + 1) / 2  # Convert to [0, 1]\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('ðŸŽ­ Generated Faces - Final Results', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Training Summary:\")\n",
    "print(f\"Final Generator Loss: {gen_losses[-1]:.4f}\")\n",
    "print(f\"Final Discriminator Loss: {disc_losses[-1]:.4f}\")\n",
    "print(f\"Total Epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent space interpolation\n",
    "def interpolate_latent_space(generator, start_noise, end_noise, steps=10):\n",
    "    \"\"\"Interpolate between two points in latent space\"\"\"\n",
    "    interpolated_images = []\n",
    "    \n",
    "    for i in range(steps):\n",
    "        alpha = i / (steps - 1)\n",
    "        interpolated_noise = (1 - alpha) * start_noise + alpha * end_noise\n",
    "        generated_image = generator(interpolated_noise, training=False)\n",
    "        interpolated_images.append(generated_image[0])\n",
    "    \n",
    "    return interpolated_images\n",
    "\n",
    "# Create interpolation\n",
    "start_noise = tf.random.normal([1, NOISE_DIM])\n",
    "end_noise = tf.random.normal([1, NOISE_DIM])\n",
    "interpolated = interpolate_latent_space(generator, start_noise, end_noise, 10)\n",
    "\n",
    "# Visualize interpolation\n",
    "fig, axes = plt.subplots(1, 10, figsize=(20, 4))\n",
    "for i, (ax, img) in enumerate(zip(axes, interpolated)):\n",
    "    display_img = (img + 1) / 2  # Convert to [0, 1]\n",
    "    ax.imshow(display_img)\n",
    "    ax.set_title(f'Step {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('ðŸŒˆ Latent Space Interpolation', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save models\n",
    "generator.save('models/generator.h5')\n",
    "discriminator.save('models/discriminator.h5')\n",
    "print(\"\\nðŸ’¾ Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've successfully built and trained a GAN for face generation! Here's what you've accomplished:\n",
    "\n",
    "âœ… **GAN Architecture**: Built generator and discriminator networks  \n",
    "âœ… **Adversarial Training**: Implemented the min-max game  \n",
    "âœ… **DCGAN**: Used convolutional layers for image generation  \n",
    "âœ… **Face Generation**: Created realistic synthetic faces  \n",
    "âœ… **Latent Space**: Explored interpolation between generated images  \n",
    "\n",
    "### ðŸš€ Next Steps:\n",
    "1. Try different GAN variants (StyleGAN, Progressive GAN)\n",
    "2. Experiment with conditional generation\n",
    "3. Implement Wasserstein GAN for stability\n",
    "4. Move on to **Project 07: Style Transfer Project**\n",
    "\n",
    "Ready for artistic AI? Let's transfer styles! ðŸŽ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
