# 🧠 Project 01 – Deep Learning Basics

This is the first project in the **Deep Learning Projects Collection**. It covers essential concepts in deep learning, helping you build a solid foundation using TensorFlow and practical notebooks in Google Colab.

---

## 📚 Concepts I Explored

- 🔹 **Introduction to Deep Learning** – What is deep learning, how it evolved, and where it's used.
- 🔹 **Perceptron & Multi-Layer Neural Networks** – Understanding how neurons and layers work.
- 🔹 **Activation Functions** – Exploring Sigmoid, ReLU, and Tanh.
- 🔹 **Backpropagation** – Learning mechanism of neural networks.
- 🔹 **Loss Functions & Optimizers** – Using Mean Squared Error, Cross-Entropy, SGD, Adam, etc.
- 🔹 **Training Techniques** – Including regularization, weight initialization, gradient descent.
- 🔹 **Google Colab + Kaggle** – Running and testing models in real cloud environments.

---

## 👨‍💻 Projects I Built

### 📈 1. Linear Regression using TensorFlow  
- Implemented a simple regression model from scratch using TensorFlow 2.x.
- Visualized predictions and loss over epochs.
- Learned how model parameters are updated via backpropagation.

### 🖼️ 2. Image Classification with Neural Networks  
- Built a neural network to classify images from the **MNIST dataset**.
- Used Dense layers with activation functions.
- Evaluated the model using accuracy and visualizations.

---

## 🗂️ Folder Structure

```bash
01_Deep_Learning_Basics/
├── regression_tensorflow.ipynb
├── image_classification_nn.ipynb
├── README.md
└── assets/ (optional: plots, images)
🚀 How to Run
Open the notebook in Google Colab

Run cells step-by-step.

Modify parameters (learning rate, batch size, etc.) and observe the effects.

🧠 Key Skills Gained
Fundamental DL concepts and terminology.

Hands-on TensorFlow practice with regression and classification.

Confidence using Colab and visualizing results.

✅ This foundational project prepares you for convolutional networks, RNNs, and more advanced deep learning tasks ahead.