🧠 Project 01 – Deep Learning Basics
Welcome to the first project in the Deep Learning Projects Collection!
This project is designed to give you a strong foundation in core deep learning concepts — from understanding how neural networks function, to building and training simple models using TensorFlow 2.x.

Ideal for beginners, this project helps you bridge the gap between theory and practice using Google Colab or Kaggle Notebooks.

📚 Concepts Explored
Concept	Description
🔹 Introduction to Deep Learning	Understanding what DL is, how it evolved from traditional ML, and its real-world applications in vision, NLP, etc.
🔹 Perceptron & MLP	Learned the structure of a perceptron and extended it to multi-layer networks.
🔹 Activation Functions	Explored Sigmoid, ReLU, and Tanh and how they add non-linearity.
🔹 Backpropagation	Studied how errors flow backward to update weights and biases.
🔹 Loss Functions	Implemented MSE for regression and Cross-Entropy for classification.
🔹 Optimizers	Compared optimization strategies like SGD and Adam.
🔹 Training Techniques	Covered regularization, batch size impact, weight initialization, and overfitting prevention.
🔹 Tooling	Trained models in Google Colab and Kaggle with free GPUs.

👨‍💻 Mini Projects Built
📈 1. Linear Regression using TensorFlow
🧮 Implemented a linear regression model using TensorFlow 2.x.

📉 Visualized the loss curve and model predictions after training.

🔁 Understood gradient descent and parameter updates step-by-step.

🖼️ 2. Image Classification with a Simple Neural Network
📊 Built a fully connected neural network to classify handwritten digits using the MNIST dataset.

🧠 Used Dense layers, activation functions, and softmax for multiclass prediction.

📈 Tracked accuracy, loss, and visualized predictions.

📂 Folder Structure
bash
Copy
Edit
01_Deep_Learning_Basics/
├── regression_tensorflow.ipynb          # Linear Regression using TensorFlow
├── image_classification_nn.ipynb        # MNIST Neural Network Classifier
├── README.md                            # Project description and usage
└── assets/                              # (Optional) Visual outputs, model diagrams
🚀 How to Run
Step 1: Open any .ipynb file in Google Colab or Kaggle
Step 2: Run cells step-by-step to understand each part
Step 3: Modify hyperparameters like:

Learning rate

Epochs

Optimizer

Activation function

📊 Observe how changes affect the loss, accuracy, and model behavior.

🧠 Key Skills Gained
Skill	Description
✅ Fundamental DL Concepts	Built confidence in concepts like perceptrons, MLPs, backpropagation
✅ TensorFlow Hands-On	Implemented models using low-code and high-level APIs
✅ Model Evaluation	Learned how to track training, test performance, and visualize outputs
✅ Environment Setup	Gained experience running notebooks in cloud environments